{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4512cd1c-aec8-4d9b-863e-b982d26f8dbb",
   "metadata": {},
   "source": [
    "# Our first Chatbot\n",
    "\n",
    "Structure of prompt messages to OpenAI\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"SYSTEM PROMPT\"},\n",
    "    {\"role\": \"user\", \"content\": \"USER PROMPT\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"ASSISTANT RESPONSE\"},\n",
    "    {\"role\": \"user\", \"content\": \"NEXT USER PROMPT\"}\n",
    "]\n",
    "```\n",
    "\n",
    "A function `chat(message, history)` can tackle this with a list of messages looking like:\n",
    "```py\n",
    "[\n",
    "    [\"user said\", \"assistant replied\"],\n",
    "    [\"then user said\", \"then assistant replied\"],\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87874dad-1ed2-4e73-9a44-6e549931a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0259f3-8458-4d2d-a8b3-9007edbd2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY not loaded.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4b5382-9f92-469f-894b-b05b6c3e5ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "def chat(*args):\n",
    "    messages = []\n",
    "    if len(args) == 1:\n",
    "        print(\"INFO: Gradio is using the modern `messages` format.\")\n",
    "        messages = args[0]\n",
    "    elif len(args) == 2:\n",
    "        print(\"INFO: Gradio is using the deprecated `(message, history)` format.\")\n",
    "        user_message, history = args\n",
    "        messages = history\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "\n",
    "    system_message = {\"role\": \"system\", \"content\": \"You are a helpful AI assistant\"}\n",
    "    messages_with_system = [system_message] + messages\n",
    "\n",
    "    try:\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages_with_system,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        full_response = \"\"\n",
    "        yield \"\"\n",
    "\n",
    "        for chunk in stream:\n",
    "            content = chunk.choices[0].delta.content or \"\"\n",
    "            if content:\n",
    "                full_response += content\n",
    "                yield full_response\n",
    "\n",
    "    except Exception as e:\n",
    "        yield f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f1377-8a28-4a2c-8a21-c237747b5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = gr.Chatbot(\n",
    "    type = \"messages\",\n",
    "    height = 500\n",
    ")\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn = chat,\n",
    "    type = \"messages\",\n",
    "    chatbot = chatbot,\n",
    "    title = \"AI Chatbot\",\n",
    "    description = \"Interract with our new AI chatbot\",\n",
    "    theme = \"soft\",\n",
    "    css = \"footer{display:none!important}\"\n",
    ")\n",
    "\n",
    "demo.launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
