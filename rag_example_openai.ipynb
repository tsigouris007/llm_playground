{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43363d87-45c8-4df9-9752-e5a55c61f32b",
   "metadata": {},
   "source": [
    "# Expert Knowledge Worker [Dumb Way]\n",
    "\n",
    "A question answering agent for a specific industry.\n",
    "\n",
    "- The agent needs to be accurate.\n",
    "- The solution has to be low cost.\n",
    "- The solution will use RAG (Retrieval Augmented Generation).\n",
    "- A first approach will be brute-force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c46bba-3f58-4e0c-afc0-d0f15d5a55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d1f2ef-acd7-4fcc-a339-ac5156a4d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY not loaded.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264fe2ba-d101-4d12-a925-278546cbe6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba48259-69fe-4f8e-89d3-0fcfa86eaa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = {}\n",
    "\n",
    "employees = glob.glob(\"knowledge-base/employees/*\")\n",
    "\n",
    "employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af03bc6-e01c-44c0-9feb-b230343eb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for employee in employees:\n",
    "    name = employee.split(' ')[-1][:-3]\n",
    "    doc = \"\"\n",
    "    with open(employee, \"r\") as f:\n",
    "        doc = f.read()\n",
    "    context[name] = doc\n",
    "\n",
    "context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2f251-3232-44d3-bb84-f732abe3a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an expert in answering accurate questions about an Insurance Tech company. Give brief, accurate answers and if you have no knowledge about something do not make up anything and inform the user of your absent knowledge instead.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9513fb7-1776-4ca3-856c-50cf924c69b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_context(message):\n",
    "    relevant_context = []\n",
    "    for context_title, context_details in context.items():\n",
    "        # This match is very dumb of course\n",
    "        if context_title in message:\n",
    "            relevant_context.append(context_details)\n",
    "    return relevant_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0269e-52ad-43eb-8993-8213e7af8799",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_relevant_context(\"Who is Emily Tran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b815c-bd6f-4806-827f-7ae2a2e5f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_relevant_context(message):\n",
    "    relevant_context = get_relevant_context(message)\n",
    "    if relevant_context:\n",
    "        message += \"\\nThe following additional context might be relevant in answering this question. If it seems irrelevant please do not make up things and inform the user of no knowledge on the topic. The context follows:\\n\"\n",
    "        for r in relevant_context:\n",
    "            message += r + \"\\n\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b6c96-067e-44e5-b80b-28d712932049",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_relevant_context(\"Who is Emily Tran\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136f6c7-fd6c-4d68-b499-4c6160304bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history\n",
    "    message = add_relevant_context(message)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c55a7c0-92b3-413b-9139-d7555059cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
