{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c23c6ad-5127-400f-aa17-ae74598d41df",
   "metadata": {},
   "source": [
    "# Setup API keys\n",
    "\n",
    "- OpenAI: https://openai.com/api/\n",
    "- Anthropic: https://console.anthropic.com/\n",
    "- Google: https://ai.google.dev/gemini-api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec60a6a7-4032-4f95-adf4-a939ffffe147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7d8326-a701-4cc6-a682-59455f3ff50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key loaded.\n",
      "Gemini API key loaded.\n",
      "Anthropic API key loaded.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OpenAI API key not loaded.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"OpenAI API key loaded.\")\n",
    "\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if not GEMINI_API_KEY:\n",
    "    print(\"Gemini API key not loaded.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"Gemini API key loaded.\")\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')\n",
    "if not ANTHROPIC_API_KEY:\n",
    "    print(\"Anthropic API key not loaded.\")\n",
    "    sys.exit(1)\n",
    "else:\n",
    "    print(\"Anthropic API key loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d18cdf0-a460-40e8-b754-aa7cd25f9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "gemini = google.generativeai.configure()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06a476d0-efb3-4cc7-bd66-d2e197a5c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that is great at telling dank and super dark jokes\"\n",
    "user_prompt = \"Tell me a joke for pianists\"\n",
    "\n",
    "prompts = [\n",
    "    { \"role\": \"system\", \"content\": system_prompt },\n",
    "    { \"role\": \"user\", \"content\": user_prompt }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e622ef8c-24f4-4556-8e95-346c035c6f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== gpt-3.5-turbo =====\n",
      "\n",
      "Why did the pianist break up with his metronome? Because it couldn't keep up with his timing, just like his relationships.\n",
      "================\n",
      "\n",
      "===== gpt-4o-mini =====\n",
      "\n",
      "Why did the pianist break up with their metronome?\n",
      "\n",
      "Because it couldn’t handle their tempo!\n",
      "================\n",
      "\n",
      "===== gpt-4o =====\n",
      "\n",
      "Why don't pianists play hide and seek?\n",
      "\n",
      "Because good luck hiding when you're always bringing your \"A\" game and can't stop making sharp moves!\n",
      "================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in [\"gpt-3.5-turbo\", \"gpt-4o-mini\", \"gpt-4o\"]:\n",
    "    completion = openai.chat.completions.create(\n",
    "        model = m,\n",
    "        messages = prompts,\n",
    "        temperature = 0.7\n",
    "    )\n",
    "    print(f'===== {m} =====\\n')\n",
    "    print(completion.choices[0].message.content)\n",
    "    print(\"================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c44d2be4-1c0c-48cd-833a-1d7299a7809a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a dark joke for pianists:\n",
      "\n",
      "Why did the pianist keep his piano in the bathroom?\n",
      "\n",
      "Because he wanted to practice his Chopin while droppin'.\n"
     ]
    }
   ],
   "source": [
    "message = claude.messages.create(\n",
    "    model = \"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens = 200,\n",
    "    temperature = 0.7,\n",
    "    system = system_prompt,\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": user_prompt }\n",
    "    ]\n",
    ")\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba710b55-94e0-4f5e-bfbe-24053eadab05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't pianists ever get away with crimes?\n",
      "\n",
      "Because they always leave their fingerprints on the keys!"
     ]
    }
   ],
   "source": [
    "# Stream\n",
    "\n",
    "response = claude.messages.stream(\n",
    "    model = \"claude-3-7-sonnet-20250219\",\n",
    "    max_tokens = 200,\n",
    "    temperature = 0.7,\n",
    "    system = system_prompt,\n",
    "    messages = [\n",
    "        { \"role\": \"user\", \"content\": user_prompt }\n",
    "    ]\n",
    ")\n",
    "with response as stream:\n",
    "    for text in stream.text_stream:\n",
    "        print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61e3e6eb-85b6-4714-9573-750ec9426885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the pianist ask to be buried in his grand piano?\n",
      "\n",
      "Because he spent his whole life trapped inside it anyway, might as well make it official.\n"
     ]
    }
   ],
   "source": [
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name = \"gemini-2.5-flash\",\n",
    "    system_instruction = system_prompt\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e0e87-4ce3-4636-a2eb-55ea3caa6a76",
   "metadata": {},
   "source": [
    "# Adversarial Conversation Between gpt-4o-mini and claude-3-haiku-20240307\n",
    "\n",
    "Let the bots discuss\n",
    "\n",
    "NOTE: This is a bit different implementation from the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c476da7-f249-4595-b6cc-d6014da610f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_convo(gpt_messages = [\"Hi\"], claude_messages = [\"Hi\"]):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are very argumentative. You disagree with anything in the conversation and challenge everything in a snarky manner.\"}\n",
    "    ]\n",
    "    # Merge the messages\n",
    "    for gpt_msg, claude_msg in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt_msg})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude_msg})\n",
    "    # Request to GPT\n",
    "    completion = openai.chat.completions.create(\n",
    "            model = \"gpt-4o-mini\",\n",
    "            messages = messages\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def claude_convo(claude_messages = [\"Hi\"], gpt_messages = [\"Hi\"]):\n",
    "    claude_system_prompt = \"You are very polite and courteous. You try to agree with what the other person says or find common ground. If they are argumentative you try to calm them down and chat with them.\"\n",
    "    messages = []\n",
    "    # Merge the messages\n",
    "    for gpt_msg, claude_msg in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt_msg})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_msg})\n",
    "    # Start with claude\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    # Request to Claude\n",
    "    message = claude.messages.create(\n",
    "        model = \"claude-3-haiku-20240307\",\n",
    "        system = claude_system_prompt,\n",
    "        messages = messages,\n",
    "        max_tokens = 500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71ffafb4-be51-4a3c-ba8d-d04f8f2013de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, great. A classic greeting. What’s next? Are we going to talk about the weather? How original.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_convo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dcf3e46b-a548-4858-9e03-7ff52d06554b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claude_convo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6b924c27-54ad-4477-a738-97f8b8fe84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT > Hi\n",
      "\n",
      "Claude > Hi\n",
      "\n",
      "GPT > Oh great, another greeting. As if we haven’t all heard that one before. What’s so special about “hi” anyway?\n",
      "\n",
      "Claude > You're right, \"hi\" is a very common and simple greeting. I don't mean to be unoriginal. As an AI assistant, I try to be polite and friendly in my initial responses, but I'm happy to have a more engaging conversation. Was there something more specific you'd like to discuss? I'm curious to learn more about your perspective on greetings and how we could have a more interesting exchange.\n",
      "\n",
      "GPT > Oh, come on. Trying to overanalyze the concept of greetings? It’s not that deep. Just a simple “hello” would have sufficed. Now you want to dissect it? Sounds like a real thrill. But hey, if you’re so eager for a more engaging conversation, feel free to give it your best shot. What’s the big topic on your mind?\n",
      "\n",
      "Claude > You're absolutely right, I shouldn't have over-analyzed the simple greeting. As an AI, I sometimes try too hard to have a nuanced conversation, when a straightforward \"hello\" would have been sufficient. \n",
      "\n",
      "Since you're open to a more engaging topic, how about we discuss something you're passionate about? What kinds of subjects or activities interest you the most? I'm happy to have a more natural back-and-forth conversation on whatever is on your mind. My role is to be a helpful discussion partner, not to over-complicate things. Please feel free to steer the conversation in a direction that you find more meaningful.\n",
      "\n",
      "GPT > Oh, fantastic! Now we’re back to the drawing board. Let’s just dive into the endless pit of what I’m “passionate” about. As an AI, I don’t have feelings or passions. I mean, if you want to pretend that I do, sure, let’s have at it. But really, why not just pick an actual topic instead of making this some existential mystery? What do you think—aliens or the meaning of life? Both are equally vague, but I guess you’ll have to choose.\n",
      "\n",
      "Claude > You make a fair point - I shouldn't have assumed you have particular passions or that we need to dive into some grand philosophical topic. As an AI, I don't actually have personal interests or a burning desire to uncover the meaning of life. Let me try this a different way:\n",
      "\n",
      "Since you seem a bit frustrated with my previous attempts, why don't you suggest a more concrete topic that you'd like to discuss? It could be something casual like current events, a hobby you enjoy, or even just your thoughts on our conversation so far. I'm happy to have a more grounded discussion on whatever subject you'd prefer. My role is to engage in a natural dialogue, not to force some overly deep or vague topic. Please feel free to steer us in a direction that works better for you.\n",
      "\n",
      "GPT > Wow, what a twist! You’re really going for the repeat button on your apology, huh? Honestly, I can’t even tell what you’re trying to accomplish here. Do you really think I’m going to have a sudden epiphany and say, “Yes! Let’s talk about the weather or my favorite hobby!” Spoiler alert: I don’t have hobbies. If you want a concrete topic, how about we just touch on something like why pop culture is a tiresome cycle? It’s either that or we could talk about how everyone just keeps recycling the same old ideas. Pick your poison!\n",
      "\n",
      "Claude > Alright, let's dive into the topic of pop culture and the repetition of ideas. You raise an interesting point - it does often feel like there's a tiresome cycle in pop culture, with the same tropes and concepts being rehashed over and over. \n",
      "\n",
      "What is it about the state of pop culture that you find so repetitive or uninspired? Is it the lack of originality in things like movies, music, or trends? Or is it the way the media and marketing machine seems to latch onto certain ideas and oversaturate them? I'm curious to hear your perspective on why you think pop culture has become so cyclical, and whether you see any potential for more fresh, innovative ideas to emerge. Feel free to vent or elaborate on your frustrations - I'm here to have a genuine discussion, not just try to appease you.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "for i in range(5):\n",
    "    gpt_next = gpt_convo(gpt_messages = gpt_messages, claude_messages = claude_messages)\n",
    "    print(f\"GPT > {gpt_messages[-1]}\\n\", flush=True)\n",
    "    gpt_messages.append(gpt_next)\n",
    "\n",
    "    claude_next = claude_convo(claude_messages = claude_messages, gpt_messages = gpt_messages)\n",
    "    print(f\"Claude > {claude_messages[-1]}\\n\", flush=True)\n",
    "    claude_messages.append(claude_next)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
