{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb62629-e2ba-4d6d-adb8-159b8f1a410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import math\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaea3f6-0949-4cdd-9b3b-f69f965d3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"OPENAI_API_KEY not loaded.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d305940d-3c35-409d-8bbf-8e332844fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_RAPID_API_KEY = os.getenv('X_RAPID_API_KEY')\n",
    "X_RAPID_API_HOST = os.getenv('X_RAPID_API_HOST')\n",
    "\n",
    "DEMO = False\n",
    "if not (X_RAPID_API_KEY or X_RAPID_API_HOST):\n",
    "    print(\"X_RAPID_API_KEY OR HOST not loaded.\")\n",
    "    DEMO = True\n",
    "\n",
    "if DEMO:\n",
    "    print(\"Running in demo mode.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9bddd5-e04e-4226-8414-c2b3ae2a3578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kelvin_to_celsius(kelvin):\n",
    "    return kelvin - 273.15\n",
    "\n",
    "def epoch_to_datetime(epoch):\n",
    "    dt_object = datetime.datetime.fromtimestamp(epoch)\n",
    "    return dt_object.strftime(\"%d/%m/%Y %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dda778-180b-4985-bc01-a80fd208a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(lat: float, lon: float, demo: bool = True):\n",
    "    if demo:\n",
    "        with open('weather/irakleio.json') as f:\n",
    "            file_content = f.read()\n",
    "        json_content = json.loads(file_content)\n",
    "    else:\n",
    "        url = \"https://open-weather13.p.rapidapi.com/fivedaysforcast\"\n",
    "        headers = {\n",
    "        \t\"x-rapidapi-key\": X_RAPID_API_KEY,\n",
    "        \t\"x-rapidapi-host\": X_RAPID_API_HOST\n",
    "        }\n",
    "        params = {\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"lang\": \"EN\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        json_content = response.json()\n",
    "\n",
    "    # Weather fields\n",
    "    today = json_content.get(\"list\", \"\")[0].get(\"main\", \"\")\n",
    "    temp = math.ceil(kelvin_to_celsius(today.get(\"temp\", \"\")))\n",
    "    feels_like = math.ceil(kelvin_to_celsius(today.get(\"feels_like\", \"\")))\n",
    "    temp_min = math.ceil(kelvin_to_celsius(today.get(\"temp_min\", \"\")))\n",
    "    temp_max = math.ceil(kelvin_to_celsius(today.get(\"temp_max\", \"\")))\n",
    "    pressure = today.get(\"pressure\", \"\")\n",
    "    sea_level = today.get(\"sea_level\", \"\")\n",
    "    humidity = today.get(\"humidity\", \"\")\n",
    "    # City fields\n",
    "    city = json_content.get(\"city\", \"\")\n",
    "    city_name = city.get(\"name\", \"\")\n",
    "    city_coord = city.get(\"coord\", \"\")\n",
    "    city_country = city.get(\"country\", \"\")\n",
    "    city_population = city.get(\"population\", \"\")\n",
    "    city_sunrise = epoch_to_datetime(city.get(\"sunrise\", \"\"))\n",
    "    city_sunset = epoch_to_datetime(city.get(\"sunset\", \"\"))\n",
    "    # Return\n",
    "    message = f\"Today's weather in {city_name} - {city_country} (population: {city_population}) is {temp}째C (feels like: {feels_like}째C) with a minimum of {temp_min}째C and a maximum of {temp_max}째C. \"\n",
    "    message += f\"The humidity is {humidity}, the pressure is {pressure} and the sea level is {sea_level}. \"\n",
    "    message += f\"The sunrise is at {city_sunrise} and the sunset is at {city_sunset}.\"\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe5aae-907d-4022-bf85-3fd2aa55f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_function = {\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get the weather given a latitude and longitude. Call this whenever you need to know the weather for a specific location (latitude, longitude), for example when a customer asks 'What is the weather like in 35.3220497, 25.1144712?'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"lat\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The latitude of the location\"\n",
    "            },\n",
    "            \"lon\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The longitude of the location\"\n",
    "            },\n",
    "            \"demo\": {\n",
    "                \"type\": \"boolean\",\n",
    "                \"description\": \"A boolean demo value to fetch data from the API or from the demo values\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"lat\", \"lon\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4043cd-b122-4cca-b033-72ac7908f19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": weather_function\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd788aa0-7c6b-4c1e-943c-7fafea7c03fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(prompt):\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful weather assistant\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True,\n",
    "        tools=tools\n",
    "    )\n",
    "\n",
    "    result = \"\"\n",
    "    tool_call_response = None\n",
    "    collected_chunks = []\n",
    "    tool_calls = []\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta\n",
    "        collected_chunks.append(chunk)\n",
    "\n",
    "        if hasattr(delta, \"content\") and delta.content:\n",
    "            result += delta.content or \"\"\n",
    "            yield result\n",
    "\n",
    "        elif hasattr(delta, \"tool_calls\") and delta.tool_calls:\n",
    "            for call in delta.tool_calls:\n",
    "                tool_calls.append(call)\n",
    "\n",
    "    if tool_calls:\n",
    "        full_args = \"\"\n",
    "        tool_name = tool_calls[0].function.name\n",
    "        for call in tool_calls:\n",
    "            full_args += call.function.arguments\n",
    "\n",
    "        print(f\"Tool call triggered: {tool_name} with args {full_args}\")\n",
    "\n",
    "        try:\n",
    "            args = json.loads(full_args)\n",
    "            if tool_name == \"get_weather\":\n",
    "                weather = get_weather(args.get(\"lat\", \"\"), args.get(\"lon\", \"\"), DEMO)\n",
    "                yield weather\n",
    "        except Exception as e:\n",
    "            yield f\"\\nError processing tool call: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ab5ca-8c7e-48fd-b385-572e75c1025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn = stream_gpt,\n",
    "    inputs = [\n",
    "        gr.Textbox(label = \"Your message\", placeholder = \"Your message\", lines = 6),\n",
    "    ],\n",
    "    outputs = [\n",
    "        gr.Markdown(label = \"Reponse\")\n",
    "    ],\n",
    "    flagging_mode = \"never\",\n",
    "    css = \"footer{display: none !important}\"\n",
    ")\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
